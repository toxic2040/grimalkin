#!/usr/bin/env python3
"""
indexer.py ‚Äî v1.2
Shared indexing logic + correct mixed-file loading
"""

from pathlib import Path

from langchain_community.document_loaders import (
    DirectoryLoader, PyPDFLoader, TextLoader, CSVLoader
)
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_ollama import OllamaEmbeddings
from langchain_community.vectorstores import FAISS

KNOWLEDGE_DIR = Path("knowledge")
FAISS_INDEX_DIR = "faiss_index"
EMBEDDING_MODEL = "nomic-embed-text"
CHUNK_SIZE = 800
CHUNK_OVERLAP = 100


def build_index():
    """Build or rebuild FAISS index ‚Äî now with full debugging and never crashes on empty."""
    print("üî® Building FAISS index from knowledge/ and ALL subfolders...")

    knowledge_dir = Path("knowledge").resolve()
    print(f"‚Üí Scanning absolute path: {knowledge_dir}")
    print(f"   Folder exists: {knowledge_dir.exists()}")
    print(f"   Is directory: {knowledge_dir.is_dir()}")

    if not knowledge_dir.exists():
        print("‚ùå 'knowledge' folder not found in current directory!")
        print("   Run: mkdir -p knowledge")
        return None

    # Debug: count files manually (super visible)
    pdf_files = list(knowledge_dir.rglob("*.pdf")) + list(knowledge_dir.rglob("*.PDF"))
    md_files  = list(knowledge_dir.rglob("*.md"))  + list(knowledge_dir.rglob("*.MD"))
    txt_files = list(knowledge_dir.rglob("*.txt")) + list(knowledge_dir.rglob("*.TXT"))
    csv_files = list(knowledge_dir.rglob("*.csv")) + list(knowledge_dir.rglob("*.CSV"))

    print(f"Found {len(pdf_files)} PDF(s), {len(md_files)} MD(s), {len(txt_files)} TXT(s), {len(csv_files)} CSV(s)")

    if len(pdf_files) + len(md_files) + len(txt_files) + len(csv_files) == 0:
        print("‚ö†Ô∏è  NO supported files found!")
        print("   Drop some .pdf / .md / .txt / .csv into knowledge/ or any subfolder")
        print("   Example: knowledge/meeting_notes/lsic_prep.md")
        return None

    # Now load with recursive=True (this is what you fixed before launch)
    pdf_docs = DirectoryLoader(
        str(knowledge_dir), glob="**/*.pdf", loader_cls=PyPDFLoader,
        show_progress=True, use_multithreading=True, recursive=True
    ).load()

    md_docs = DirectoryLoader(
        str(knowledge_dir), glob="**/*.md", loader_cls=TextLoader,
        show_progress=True, use_multithreading=True, recursive=True
    ).load()

    txt_docs = DirectoryLoader(
        str(knowledge_dir), glob="**/*.txt", loader_cls=TextLoader,
        show_progress=True, use_multithreading=True, recursive=True
    ).load()

    csv_docs = DirectoryLoader(
        str(knowledge_dir), glob="**/*.csv", loader_cls=CSVLoader,
        show_progress=True, use_multithreading=True, recursive=True
    ).load()

    all_docs = pdf_docs + md_docs + txt_docs + csv_docs
    print(f"‚úÖ Successfully loaded {len(all_docs)} documents (including nested folders)")

    splitter = RecursiveCharacterTextSplitter(
        chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP
    )
    chunks = splitter.split_documents(all_docs)
    print(f"Created {len(chunks)} chunks")

    embeddings = OllamaEmbeddings(model=EMBEDDING_MODEL)
    vectorstore = FAISS.from_documents(chunks, embeddings)
    vectorstore.save_local(FAISS_INDEX_DIR)

    print("üéâ Index built successfully!")
    print(f"   Saved to: {FAISS_INDEX_DIR}/")
    return vectorstore

if __name__ == "__main__":
    build_index()
